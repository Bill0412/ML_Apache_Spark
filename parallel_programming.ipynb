{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experience Parallel Programming on Apache Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1st Statistical Moment.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 1000,\n",
       " 10000]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(list(range(100)) + [100, 1000, 10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize(list(range(100)) + [100, 1000, 10000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean\n",
    "Calculate the mean of the data generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155.8252427184466\n"
     ]
    }
   ],
   "source": [
    "sum = rdd.sum()\n",
    "n = rdd.count()\n",
    "mean = sum / n\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The median is an **out-lier** resistant version of the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "sortedAndIndexed = rdd.sortBy(lambda x : x).zipWithIndex().map(lambda val: (val[1], val[0]))\n",
    "n = sortedAndIndexed.count()\n",
    "if(n % 2 == 1):\n",
    "    index = (n - 1) / 2\n",
    "    print(sortedAndIndexed.lookup(index)[0])\n",
    "else:\n",
    "    index1 = (n / 2) - 1\n",
    "    index2 = n / 2\n",
    "    value1 = sortedAndIndexed.lookup(index1)[0]\n",
    "    value2 = sortedAndIndexed.lookup(index2)[0]\n",
    "    print((value1 + value2) / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **2nd Statistical Moment**. \n",
    "How wide the data is spread around the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "979.5845902523644"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "sd = sqrt(rdd.map(lambda x : pow(x - mean, 2)).sum() / n)\n",
    "sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skewness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skewness is the **3rd Statistical Moment**. It measures how asymmetric data is spread about the mean.<br>\n",
    "![](images/skewness.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "990.5891089108911 94.15273288177377\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize(list(range(100)) + [1000]*10000)\n",
    "sum = rdd.sum()\n",
    "n = rdd.count()\n",
    "mean = sum / n\n",
    "sd = sqrt(rdd.map(lambda x : pow(x - mean, 2)).sum() / n)\n",
    "print(mean, sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-100132.30520317465"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skewness = rdd.map(lambda x : pow(x - mean, 3) / pow(sd, 3)).sum()\n",
    "skewness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, add the normalization term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.914089624076698"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skewness = (1 / n) * rdd.map(lambda x : pow(x - mean, 3) / pow(sd, 3)).sum()\n",
    "skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.911560206061798"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize(list(range(100)) + [-1000]*10000)\n",
    "sum = rdd.sum()\n",
    "n = rdd.count()\n",
    "mean = sum / n\n",
    "sd = sqrt(rdd.map(lambda x : pow(x - mean, 2)).sum() / n)\n",
    "skewness = (1 / n) * rdd.map(lambda x : pow(x - mean, 3) / pow(sd, 3)).sum()\n",
    "skewness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kurtosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **4th Statistical Moment**\n",
    "- The higher the kurtosis measure is, the more outliers are present and the longer the tails of the distribution in the histogram are.\n",
    "- **Outlier**: In statistics, an outlier is a data point that differs significantly from other observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![kurtosis](images/kurtosis.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.3167193433139"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kurtosis = 1 / n * rdd.map(lambda x : pow(x - mean, 4) / pow(sd, 4)).sum()\n",
    "kurtosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance, Covariance matrices, Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We firstly take an example where the 2 columns of data totally correlate with each other, with +1 as their correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "rddX = sc.parallelize(range(100))\n",
    "rddY = sc.parallelize(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.5\n",
      "49.5\n"
     ]
    }
   ],
   "source": [
    "meanX = rddX.sum() / rddX.count()\n",
    "meanY = rddY.sum() / rddY.count()\n",
    "print(meanX)\n",
    "print(meanY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (1, 1),\n",
       " (2, 2),\n",
       " (3, 3),\n",
       " (4, 4),\n",
       " (5, 5),\n",
       " (6, 6),\n",
       " (7, 7),\n",
       " (8, 8),\n",
       " (9, 9)]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddXY = rddX.zip(rddY)\n",
    "rddXY.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "833.25"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covXY = rddXY.map(lambda row : (row[0] - meanX) * (row[1] - meanY)).sum() / rddXY.count()\n",
    "covXY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.86607004772212\n",
      "28.86607004772212\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "n = rddXY.count()\n",
    "sdX = sqrt(rddX.map(lambda x: pow(x - meanX, 2)).sum() / n)\n",
    "sdY = sqrt(rddX.map(lambda x: pow(x - meanY, 2)).sum() / n)\n",
    "print(sdX)\n",
    "print(sdY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrXY = covXY / (sdX * sdY)\n",
    "corrXY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 100, 99, 63],\n",
       " [1, 101, 98, 9],\n",
       " [2, 102, 97, 79],\n",
       " [3, 103, 96, 80],\n",
       " [4, 104, 95, 76],\n",
       " [5, 105, 94, 72],\n",
       " [6, 106, 93, 97],\n",
       " [7, 107, 92, 17],\n",
       " [8, 108, 91, 39],\n",
       " [9, 109, 90, 78]]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from pyspark.mllib.stat import Statistics\n",
    "column1 = sc.parallelize(range(100)).repartition(1)\n",
    "column2 = sc.parallelize(range(100, 200)).repartition(1)\n",
    "column3 = sc.parallelize(reversed(range(100))).repartition(1)\n",
    "column4 = sc.parallelize(random.sample(range(100), 100)).repartition(1)\n",
    "data = column1.zip(column2).zip(column3).zip(column4).map(lambda row: [row[0][0][0], row[0][0][1], row[0][1], row[1]])\n",
    "data.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  1.        , -1.        , -0.05220522],\n",
       "       [ 1.        ,  1.        , -1.        , -0.05220522],\n",
       "       [-1.        , -1.        ,  1.        ,  0.05220522],\n",
       "       [-0.05220522, -0.05220522,  0.05220522,  1.        ]])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Statistics.corr(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
