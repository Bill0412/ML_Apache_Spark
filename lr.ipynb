{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "sc = SparkContext('local')\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+--------------------+-----------+\n",
      "|  x|  y|  z|              source|      class|\n",
      "+---+---+---+--------------------+-----------+\n",
      "| 22| 49| 35|Accelerometer-201...|Brush_teeth|\n",
      "| 22| 49| 35|Accelerometer-201...|Brush_teeth|\n",
      "| 22| 52| 35|Accelerometer-201...|Brush_teeth|\n",
      "| 22| 52| 35|Accelerometer-201...|Brush_teeth|\n",
      "| 21| 52| 34|Accelerometer-201...|Brush_teeth|\n",
      "| 22| 51| 34|Accelerometer-201...|Brush_teeth|\n",
      "| 20| 50| 35|Accelerometer-201...|Brush_teeth|\n",
      "| 22| 52| 34|Accelerometer-201...|Brush_teeth|\n",
      "| 22| 50| 34|Accelerometer-201...|Brush_teeth|\n",
      "| 22| 51| 35|Accelerometer-201...|Brush_teeth|\n",
      "| 21| 51| 33|Accelerometer-201...|Brush_teeth|\n",
      "| 20| 50| 34|Accelerometer-201...|Brush_teeth|\n",
      "| 21| 49| 33|Accelerometer-201...|Brush_teeth|\n",
      "| 21| 49| 33|Accelerometer-201...|Brush_teeth|\n",
      "| 20| 51| 35|Accelerometer-201...|Brush_teeth|\n",
      "| 18| 49| 34|Accelerometer-201...|Brush_teeth|\n",
      "| 19| 48| 34|Accelerometer-201...|Brush_teeth|\n",
      "| 16| 53| 34|Accelerometer-201...|Brush_teeth|\n",
      "| 18| 52| 35|Accelerometer-201...|Brush_teeth|\n",
      "| 18| 51| 32|Accelerometer-201...|Brush_teeth|\n",
      "+---+---+---+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_data_1 = spark.read.parquet('hmp.parquet')\n",
    "df_data_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------+\n",
      "|             label|         class|\n",
      "+------------------+--------------+\n",
      "| 8959.680239829991| Use_telephone|\n",
      "| 9737.511232342687| Standup_chair|\n",
      "| 12542.96539897962|      Eat_meat|\n",
      "|13225.945637269193|     Getup_bed|\n",
      "|15003.269043778426|   Drink_glass|\n",
      "|14454.885091207056|    Pour_water|\n",
      "|10616.408809008817|     Comb_hair|\n",
      "|16537.370891408344|          Walk|\n",
      "|11082.626493751379|  Climb_stairs|\n",
      "|10261.338314274606| Sitdown_chair|\n",
      "|6783.4063714331605|   Liedown_bed|\n",
      "| 7173.493500380411|Descend_stairs|\n",
      "| 11785.39634462923|   Brush_teeth|\n",
      "| 6071.460120926432|      Eat_soup|\n",
      "+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_energy = spark.sql(\"\"\"\n",
    "    \n",
    "select sqrt(sum(x*x)+sum(y*y)+sum(z*z)) as label, class from df group by class \n",
    "    \n",
    "\"\"\")\n",
    "df_energy.show()\n",
    "df_energy.createOrReplaceTempView('df_energy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+--------------------+-----------+-----------------+-----------+\n",
      "|  x|  y|  z|              source|      class|            label|      class|\n",
      "+---+---+---+--------------------+-----------+-----------------+-----------+\n",
      "| 22| 49| 35|Accelerometer-201...|Brush_teeth|11785.39634462923|Brush_teeth|\n",
      "| 22| 49| 35|Accelerometer-201...|Brush_teeth|11785.39634462923|Brush_teeth|\n",
      "| 22| 52| 35|Accelerometer-201...|Brush_teeth|11785.39634462923|Brush_teeth|\n",
      "| 22| 52| 35|Accelerometer-201...|Brush_teeth|11785.39634462923|Brush_teeth|\n",
      "| 21| 52| 34|Accelerometer-201...|Brush_teeth|11785.39634462923|Brush_teeth|\n",
      "| 22| 51| 34|Accelerometer-201...|Brush_teeth|11785.39634462923|Brush_teeth|\n",
      "| 20| 50| 35|Accelerometer-201...|Brush_teeth|11785.39634462923|Brush_teeth|\n",
      "| 22| 52| 34|Accelerometer-201...|Brush_teeth|11785.39634462923|Brush_teeth|\n",
      "| 22| 50| 34|Accelerometer-201...|Brush_teeth|11785.39634462923|Brush_teeth|\n",
      "| 22| 51| 35|Accelerometer-201...|Brush_teeth|11785.39634462923|Brush_teeth|\n",
      "| 21| 51| 33|Accelerometer-201...|Brush_teeth|11785.39634462923|Brush_teeth|\n",
      "| 20| 50| 34|Accelerometer-201...|Brush_teeth|11785.39634462923|Brush_teeth|\n",
      "| 21| 49| 33|Accelerometer-201...|Brush_teeth|11785.39634462923|Brush_teeth|\n",
      "| 21| 49| 33|Accelerometer-201...|Brush_teeth|11785.39634462923|Brush_teeth|\n",
      "| 20| 51| 35|Accelerometer-201...|Brush_teeth|11785.39634462923|Brush_teeth|\n",
      "| 18| 49| 34|Accelerometer-201...|Brush_teeth|11785.39634462923|Brush_teeth|\n",
      "| 19| 48| 34|Accelerometer-201...|Brush_teeth|11785.39634462923|Brush_teeth|\n",
      "| 16| 53| 34|Accelerometer-201...|Brush_teeth|11785.39634462923|Brush_teeth|\n",
      "| 18| 52| 35|Accelerometer-201...|Brush_teeth|11785.39634462923|Brush_teeth|\n",
      "| 18| 51| 32|Accelerometer-201...|Brush_teeth|11785.39634462923|Brush_teeth|\n",
      "+---+---+---+--------------------+-----------+-----------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_join = spark.sql(\"\"\"\n",
    "\n",
    "select * from df inner join df_energy on df.class=df_energy.class\n",
    "\n",
    "\"\"\")\n",
    "df_join.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import Normalizer\n",
    "\n",
    "vectorAssembler = VectorAssembler(inputCols=[\"x\", \"y\", \"z\"],\n",
    "                                 outputCol=\"features\")\n",
    "normalizer = Normalizer(inputCol=\"features\", outputCol=\"features_norm\", p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[vectorAssembler, normalizer, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(df_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(df_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03259100556263628"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.stages[2].summary.r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
